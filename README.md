
# ğŸ§  Scientific Paper Scout

**Scientific Paper Scout** is a local AI assistant that summarizes scientific papers (PDFs) using powerful LLMs like Groq's LLaMA 3. It features a FastAPI backend where you can upload a PDF and get a concise, meaningful summary of its content.

---

## ğŸš€ Features

- ğŸ” Extracts and parses scientific paper PDFs
- ğŸ§  Summarizes papers using Groqâ€™s LLaMA 3 (`llama3-8b-8192`)
- âš¡ FastAPI backend with interactive Swagger UI
- ğŸ” Secure, modular, and `.env`-configurable

---
```markdown

## ğŸ“ Project Structure

scientific-paper-scout/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ main.py               # Entry point for agents
â”‚   â”œâ”€â”€ agent_host.py         # Hosts the agent for orchestrating tasks
â”‚   â”œâ”€â”€ llm_provider.py       # LLM integration logic (Groq by default)
â”‚   â”œâ”€â”€ logger.py             # Centralized logging setup
â”‚   â””â”€â”€ .env                  # Environment configuration (not committed)
â”œâ”€â”€ mcp_servers/
â”‚   â”œâ”€â”€ paper_search/
â”‚   â”‚   â””â”€â”€ server.py         # (Optional) Endpoint for paper search (future scope)
â”‚   â””â”€â”€ pdf_summarize/
â”‚       â””â”€â”€ server.py         # Main FastAPI server for PDF summarization
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ utils.py              # Common helper functions
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/scientific_paper_scout.git
cd scientific_paper_scout
```

### 2. Set up a virtual environment

```bash
# On Linux/macOS
python -m venv venv
source venv/bin/activate

# On Windows
python -m venv venv
venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure environment variables

Create a `.env` file in the root directory with the following content:

```env
LLM_PROVIDER=groq
GROQ_API_KEY=your_groq_api_key
```

---

## â–¶ï¸ Run the Server

Start the PDF summarization server using:

```bash
uvicorn mcp_servers.pdf_summarize.server:app --reload
```

Then open your browser to the Swagger UI:

ğŸ‘‰ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ§  LLM Support

Currently supported:

* âœ… **Groq** (`llama3-8b-8192`)

> You can easily extend support to other providers like OpenAI or Anthropic by modifying `agent/llm_provider.py`.

---

## ğŸ“ Example API Response

```json
{
  "summary": "This paper explores the use of deep learning methods in protein structure prediction..."
}
```

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ feel free to use, modify, and distribute it.

---

## âœ¨ Acknowledgements

* [FastAPI](https://fastapi.tiangolo.com/)
* [Groq](https://groq.com/)
* [PyMuPDF](https://pymupdf.readthedocs.io/)
```

